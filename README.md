# ğŸ§ Real-Time Voice Emotion Detector

This project uses machine learning to detect human emotions such as **happy**, **sad**, **angry**, and **neutral** from real-time speech using your microphone. It combines classical ML techniques with live audio feature extraction to classify emotions on the fly.

---

## ğŸ“Œ Features

- ğŸ™ï¸ Record speech from your microphone
- ğŸ§  Classify emotions using Random Forest & SVM
- ğŸ“Š Hyperparameter tuning with GridSearchCV
- ğŸ“ˆ Accuracy comparison & feature importance visualization
- ğŸ” Real-time emotion prediction with text-to-speech feedback
- ğŸ”§ Improved prediction with normalized audio input

---

## ğŸš€ How to Run

# Step 1: Clone the repository
git clone https://github.com/yourusername/real-time-voice-emotion-detector.git
cd real-time-voice-emotion-detector

# Step 2: Install required packages
pip install -r requirements.txt

# Step 3: Launch the notebook
jupyter notebook notebooks/Emotion_Detection.ipynb

---

## ğŸ“¦ Requirements
- Python 3.9+
- numpy
- pandas
- scikit-learn
- librosa
- sounddevice
- matplotlib
- seaborn
- joblib
- pyttsx3

---

## âœ… Results

- Accuracy (Random Forest): **~65â€“75%** depending on parameter tuning
- Real-time predictions may vary due to microphone quality and ambient noise
- The model was trained on RAVDESS dataset, which contains acted emotions â€” this limits real-world generalization
- Improvements were made using audio normalization and feature tuning

---

## ğŸ”® Future Enhancements

- Train using your own voice samples for better real-time accuracy
- Add Streamlit app for interactive web-based prediction
- Integrate deep learning models like Wav2Vec2 for higher generalization

---


