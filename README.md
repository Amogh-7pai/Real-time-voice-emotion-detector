# ğŸ§ Real-Time Voice Emotion Detector

This project uses machine learning to detect human emotions such as **happy**, **sad**, **angry**, and **neutral** from real-time speech using your microphone. It combines classical ML techniques with live audio feature extraction to classify emotions on the fly.

---

## ğŸ“Œ Features

- ğŸ™ï¸ Record speech from your microphone
- ğŸ§  Classify emotions using Random Forest & SVM
- ğŸ“Š Hyperparameter tuning with GridSearchCV
- ğŸ“ˆ Accuracy comparison & feature importance visualization
- ğŸ” Real-time emotion prediction with text-to-speech feedback
- ğŸ”§ Improved prediction with normalized audio input

---

## ğŸš€ How to Run

# Step 1: Clone the repository
git clone https://github.com/yourusername/real-time-voice-emotion-detector.git
cd real-time-voice-emotion-detector

# Step 2: Install required packages
pip install -r requirements.txt

# Step 3: Launch the notebook
jupyter notebook notebooks/Emotion_Detection.ipynb

---

## ğŸ§° Tech Stack

- Python 3.9+
- scikit-learn
- librosa
- sounddevice
- matplotlib / seaborn
- pyttsx3 (for speech output)

---
ğŸ“‚ Folder Structure
bash
Copy code
ğŸ“ data/
 â””â”€â”€ Audio_Speech_Actors_01-24/       # RAVDESS dataset
ğŸ“ models/
 â””â”€â”€ emotion_model.pkl                # Trained model
 â””â”€â”€ scaler.pkl                       # Scaler for normalization
ğŸ“ notebooks/
 â””â”€â”€ Emotion_Detection.ipynb          # Main notebook
ğŸ“„ README.md
ğŸ“„ requirements.txt

